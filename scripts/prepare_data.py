#!/usr/bin/env python3
"""
Script Ä‘á»ƒ chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u song ngá»¯ tá»« file text sang JSON format cho training
"""

import json
import argparse
from pathlib import Path
from sklearn.model_selection import train_test_split

def read_parallel_files(vi_file, en_file):
    """Äá»c cÃ¡c file song ngá»¯ vÃ  tráº£ vá» danh sÃ¡ch cÃ¡c cáº·p cÃ¢u"""
    print(f"ğŸ“– Äang Ä‘á»c file: {vi_file} vÃ  {en_file}")
    
    with open(vi_file, 'r', encoding='utf-8') as f_vi:
        vi_lines = [line.strip() for line in f_vi if line.strip()]
    
    with open(en_file, 'r', encoding='utf-8') as f_en:
        en_lines = [line.strip() for line in f_en if line.strip()]
    
    if len(vi_lines) != len(en_lines):
        print(f"âš ï¸  Cáº£nh bÃ¡o: Sá»‘ dÃ²ng khÃ´ng khá»›p! Vi: {len(vi_lines)}, En: {len(en_lines)}")
        min_len = min(len(vi_lines), len(en_lines))
        vi_lines = vi_lines[:min_len]
        en_lines = en_lines[:min_len]
        print(f"   ÄÃ£ cáº¯t xuá»‘ng {min_len} cáº·p cÃ¢u")
    
    return list(zip(vi_lines, en_lines))

def create_json_dataset(pairs, direction, output_file, test_size=0.1):
    """
    Táº¡o dataset JSON tá»« cÃ¡c cáº·p cÃ¢u
    
    Args:
        pairs: List of (vi_text, en_text) tuples
        direction: "en-vi" hoáº·c "vi-en"
        output_file: File output JSON
        test_size: Tá»· lá»‡ validation set
    """
    print(f"ğŸ“ Äang táº¡o dataset {direction}...")
    
    # Táº¡o train/val split
    train_pairs, val_pairs = train_test_split(
        pairs, 
        test_size=test_size, 
        random_state=42,
        shuffle=True
    )
    
    print(f"   Train: {len(train_pairs)} cáº·p cÃ¢u")
    print(f"   Val: {len(val_pairs)} cáº·p cÃ¢u")
    
    # Táº¡o train dataset
    train_data = []
    for vi_text, en_text in train_pairs:
        if direction == "en-vi":
            item = {
                "instruction": "Translate the following English text to Vietnamese:",
                "input": en_text,
                "output": vi_text
            }
        else:  # vi-en
            item = {
                "instruction": "Translate the following Vietnamese text to English:",
                "input": vi_text,
                "output": en_text
            }
        train_data.append(item)
    
    # Táº¡o val dataset
    val_data = []
    for vi_text, en_text in val_pairs:
        if direction == "en-vi":
            item = {
                "instruction": "Translate the following English text to Vietnamese:",
                "input": en_text,
                "output": vi_text
            }
        else:  # vi-en
            item = {
                "instruction": "Translate the following Vietnamese text to English:",
                "input": vi_text,
                "output": en_text
            }
        val_data.append(item)
    
    # LÆ°u train file
    train_file = output_file.replace('.json', '_train.json')
    with open(train_file, 'w', encoding='utf-8') as f:
        json.dump(train_data, f, ensure_ascii=False, indent=2)
    print(f"âœ… ÄÃ£ lÆ°u train file: {train_file}")
    
    # LÆ°u val file
    val_file = output_file.replace('.json', '_val.json')
    with open(val_file, 'w', encoding='utf-8') as f:
        json.dump(val_data, f, ensure_ascii=False, indent=2)
    print(f"âœ… ÄÃ£ lÆ°u val file: {val_file}")
    
    return train_file, val_file

def main():
    parser = argparse.ArgumentParser(description="Chuáº©n bá»‹ dá»¯ liá»‡u cho training")
    parser.add_argument("--vi-file", type=str, 
                       default="data/raw/train.vi.txt",
                       help="File tiáº¿ng Viá»‡t")
    parser.add_argument("--en-file", type=str,
                       default="data/raw/train.en.txt",
                       help="File tiáº¿ng Anh")
    parser.add_argument("--output-dir", type=str,
                       default="data",
                       help="ThÆ° má»¥c output")
    parser.add_argument("--test-size", type=float, default=0.1,
                       help="Tá»· lá»‡ validation set (default: 0.1)")
    
    args = parser.parse_args()
    
    # Äáº£m báº£o output directory tá»“n táº¡i
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("ğŸš€ Báº¯t Ä‘áº§u xá»­ lÃ½ dá»¯ liá»‡u...")
    print("=" * 60)
    
    # Äá»c file song ngá»¯
    pairs = read_parallel_files(args.vi_file, args.en_file)
    print(f"âœ… ÄÃ£ Ä‘á»c {len(pairs)} cáº·p cÃ¢u")
    print()
    
    # Táº¡o dataset cho cáº£ hai chiá»u
    print("ğŸ“Œ Táº¡o dataset Anh -> Viá»‡t")
    print("-" * 60)
    en_vi_train, en_vi_val = create_json_dataset(
        pairs,
        "en-vi",
        str(output_dir / "vlsp_medical_en_vi.json"),
        args.test_size
    )
    print()
    
    print("ğŸ“Œ Táº¡o dataset Viá»‡t -> Anh")
    print("-" * 60)
    vi_en_train, vi_en_val = create_json_dataset(
        pairs,
        "vi-en",
        str(output_dir / "vlsp_medical_vi_en.json"),
        args.test_size
    )
    print()
    
    print("=" * 60)
    print("âœ… HoÃ n thÃ nh xá»­ lÃ½ dá»¯ liá»‡u!")
    print()
    print("ğŸ“ CÃ¡c file Ä‘Ã£ táº¡o:")
    print(f"   - {en_vi_train}")
    print(f"   - {en_vi_val}")
    print(f"   - {vi_en_train}")
    print(f"   - {vi_en_val}")

if __name__ == "__main__":
    main()

