#!/usr/bin/env python3
"""
Batch inference vá»›i Unsloth á»Ÿ 4-bit Ä‘á»ƒ trÃ¡nh OOM trÃªn RTX 5060 Ti.

Cháº¡y:
    cd /home/alida/Documents/Cursor/NLP_fine_tun
    python final_test_unsloth.py
"""

from unsloth import FastLanguageModel
import torch
import json

try:
    from tqdm import tqdm
except ImportError:  # Fallback náº¿u chÆ°a cÃ i tqdm
    def tqdm(x, **kwargs):
        return x


# --- Cáº¤U HÃŒNH ---
# ÄÆ°á»ng dáº«n model Ä‘Ã£ merge
MODEL_PATH = "/home/alida/Documents/Cursor/NLP_fine_tun/final_models/Qwen2.5-7B-Medical-Full-Bin"

# (Tuá»³ chá»n) File test JSON náº¿u sau nÃ y báº¡n muá»‘n dÃ¹ng
INPUT_FILE = "data/public_test.json"
OUTPUT_FILE = "predictions.jsonl"


print(f"â³ Äang load model 4-bit tá»«: {MODEL_PATH}...")
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name=MODEL_PATH,
    max_seq_length=2048,
    dtype=None,
    load_in_4bit=True,  # CHÃŒA KHÃ“A Äá»‚ KHÃ”NG Bá»Š OOM
)
FastLanguageModel.for_inference(model)  # TÄƒng tá»‘c 2x


def batch_translate(texts, batch_size: int = 8):
    """Dá»‹ch batch cÃ¢u Anh->Viá»‡t vá»›i prompt Ä‘Æ¡n giáº£n."""
    results = []

    prompts = [
        (f"Translate to Vietnamese: {text}" if "Translate" not in text else text)
        for text in texts
    ]

    for i in tqdm(range(0, len(prompts), batch_size), desc="Äang dá»‹ch..."):
        batch = prompts[i : i + batch_size]

        inputs = tokenizer(
            batch,
            return_tensors="pt",
            padding=True,
        )
        inputs = {k: v.to(model.device) for k, v in inputs.items()}

        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=256,
                use_cache=True,
                pad_token_id=tokenizer.eos_token_id,
            )

        decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)
        cleaned = [d.split("Vietnamese:")[-1].strip() for d in decoded]
        results.extend(cleaned)

    return results


def main():
    # --- CHáº Y THá»¬ Vá»šI Dá»® LIá»†U MáºªU ---
    test_sentences = [
        "The patient was diagnosed with type 2 diabetes.",
        "Acute respiratory distress syndrome (ARDS) is a life-threatening condition.",
        "DÃ¹ng thuá»‘c sau khi Äƒn 30 phÃºt.",
        "Bá»‡nh nhÃ¢n cÃ³ tiá»n sá»­ cao huyáº¿t Ã¡p vÃ´ cÄƒn.",
    ]

    print("\nğŸš€ Báº¯t Ä‘áº§u test thá»­...")
    translations = batch_translate(test_sentences, batch_size=4)

    for src, tgt in zip(test_sentences, translations):
        print("-" * 40)
        print(f"Input:  {src}")
        print(f"Output: {tgt}")

    print("\nâœ… HoÃ n táº¥t! Model Ä‘ang cháº¡y á»Ÿ cháº¿ Ä‘á»™ 4-bit, an toÃ n VRAM.")


if __name__ == "__main__":
    main()


